# Linear regression

## Background

- Simplest regression model: $y=a+bx+error$
- Additional predictors: : $y=\beta_0+\beta_1x_1+...+\beta_kx_k+error$
- Nonlinear models: $\log y=a+b \log x+error$
- Nonadditive models: $y=\beta_0+\beta_1x_1+\beta_2x_2+\beta_3x_1x_2+error$
- Generalized linear models: Non-normal additive errors with a function that "links" the linear predictor with the outcome.

## Simple regression with fake data

Same as Chapter \@ref(intro)

```{r warning=FALSE,message=FALSE}
x=1:20
n=length(x)
a=0.2
b=0.3
sigma=0.5
y=a + b*x + sigma*rnorm(n)
```

```{r warning=FALSE,message=FALSE}
fit=lm(y~x)
summary(fit)
```

```{r echo=FALSE}
kable(confint(fit), caption = '95% CI for intercept and slope',
  booktabs = TRUE)
```

*Questions*

1. Are estimates consistent with true values?
2. What can you tell about the uncertainty surrounding the coefficients?

We can also plot the data and fitter regression line (Figure \@ref(fig:fig1)).

```{r fig1, warning=FALSE,message=FALSE, fig.cap="Observed and fitted"}
plot(x, y, main="Data and fitted regression line")
a_hat=coef(fit)[1]
b_hat=coef(fit)[2]
abline(a_hat, b_hat)
```

## Interpretation of coefficients and model diagnostics

*Linear regression assumptions*

1. Normality of residuals.
2. Linear relationship.
3. Constant variance.
4. $y_i$ are independent.


Let's start using real data. Below we can see a brief description about the dataset used in this example.

```{r warning=FALSE,message=FALSE,eval=FALSE}
install.packages("datarium") # Install to access the dataset
?marketing #description of the dataset
library(datarium)
head(marketing)
```

```{r warning=FALSE,message=FALSE,echo=FALSE}
library(datarium)
kable(head(marketing), booktabs = TRUE)
```

We build a model to predict sales on the basis of advertising budget spent in youtube **and** facebook. It is important to notice the nonadditive model used here and the implications of interaction terms.

```{r warning=FALSE,message=FALSE}
fit2=lm(sales ~ youtube*facebook, data = marketing)
summary(fit2)
```

Also we plot some regression diagnostics.

```{r fig2, warning=FALSE,message=FALSE}
plot(fit2)
```

## Outliers and how to diagnose them

Let's recall our linear model, i.e., $y_i=a+bx_i+\epsilon_i,\quad \epsilon_i\sim \mathcal{N}(0,\sigma)$. Why is important to check the outliers after fitting our model? Because sometimes we can encounter potential outliers that could influence the regression model in the sense of pulling our fitted model towards these outliers. 

### Studentized residuals

After fitting our linear model, we get

$$
y_i=\hat{a}+\hat{b}x_i+d_i \implies d_i=y_i-\hat{y_i}
$$
where $d_i$ denotes the residual for observation $i$ and $\hat{y_i}=\hat{a}+\hat{b}x_i$. Let's plot again our fitted values vs residuals in our previous model. How large is large? 

```{r fig3, warning=FALSE,message=FALSE}
plot(fit2,1)
```

In order to answer the previous question, we standardize our residuals, i.e.,

$$
t_i=\frac{d_i}{sd(d_i)}
$$
This studentized residuals follow a student's t distribution, i.e., $t_i\sim t_{n-p-1}$ where $p$ is the number of coefficients in our regression model.

**Questions**

1. Why do residuals $>2$ warrant attention?

### Difference in Fits (DFFITS)

Are outliers bad when fitting a linear model? Not necessarily. We can have outliers which are not influential in our fitted model. The idea behind diagnosing influential observations is to delete the observations one at a time, each time refitting the regression model on the remaining $nâ€“1$ observations. 

The difference in fits for observation $i$, denoted $DFFITS_i$, is defined as:

$$
DFFITS_i=\frac{\hat{y_i}-\hat{y}_{(i)}}{sd(\hat{y_i}-\hat{y}_{(i)})}
$$
where $\hat{y}_{(i)}$ denotes the fitted response when observation $i$ is removed. Going back to our previous example, Figure \@ref(fig:fig4) shows how influential our observations can be

```{r fig4, warning=FALSE,message=FALSE,fig.cap="DFFITS"}
plot(dffits(fit2))
```

$DFFITS_i$ can also be expressed as

$$
DFFITS_i=t_{(i)}\sqrt{\frac{h_{ii}}{1-h_{ii}}}
$$

where $t_{(i)}$ is the externally studentized residual and $h_ii$ represents the **leverage**. The leverage $h_ii$ is a measure of the distance between the $x$ value for the $i$th data point and the mean of the $x$ values for all $n$ data points. For a perfectly balanced experimental design, the leverage for each point is $p/n$, therefore

$$
DFFITS_i=t_{(i)}\sqrt{\frac{p}{n}}
$$
